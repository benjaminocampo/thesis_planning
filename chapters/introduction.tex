\chapter{Introducción}
\label{ch:into}

\section{Contexto y motivación}
La planificación automática, o simplemente \emph{planning}, es una de las áreas
centrales de la inteligencia artificial debido a su extenso uso en dominios,
tales como, control de misiones espaciales \citep{RabideauG-et-al-2001}, manejo
de crisis \citep{Bienkowki-1995}, generación de textos narrativos
\citep{Goudoulakis-et-al-2016}, o robótica \citep{Munoz-et-al-2016}.

El objetivo es definir un modelo que simule una tarea descripta por medio de una
especificación que detalle sus componentes. Estas son el estado inicial, la
meta, y un conjunto de acciones. El estado inicial describe las propiedades
verdaderas iniciales del problema. La meta o estado final representa cuáles son
las propiedades que deben ser verdaderas para finalizar la tarea. Y el conjunto
de acciones está compuesto de transformadores que alteran si una propiedad pasa
a ser verdadera o deja de serlo. Este conjunto de propiedades recibe el nombre
de estado, y modelan que propiedades son verdaderas y falsas, y a que estados
puede cambiar por medio de alguna acción. Si se obtiene una secuencia de
acciones que sea aplicable en el estado inicial, y que luego de su ejecución
conlleve a la meta, entonces dicha secuencia es considerada un plan del
problema.

Para hallar un plan que resuelva la tarea, se realizan técnicas de búsqueda y
optimización, efectuadas por \emph{planificadores}, algoritmos que computan el
comportamiento de un agente por medio de una descripción del problema comúnmente
definida en el \emph{Planning Domain Definition Language} (PDDL). En PDDL, se
especifican las propiedades del entorno en términos de predicados, y las
transformaciones por medio de esquemas de acción. Estas consisten en expresiones
parametrizadas que pueden ser instanciadas por un conjunto de objetos. El
planificador por medio de la especificación, define un espacio de búsqueda sobre
el cual encontrar un plan.

Sin embargo, la mayoría de los planificadores trabajan sobre una representación
sin variables libres. Por consecuente, estos computan todas las instanciaciones
que asignan los objetos a los argumentos de los predicados y esquemas de acción
definidos por la especificación en PDDL del problema. Este proceso, conocido
como \emph{grounding}, es exponencial en la cantidad de argumentos de los
esquemas de acción y predicados, llegando a obtener una cantidad inmensurable de
instancias cuando el número de parámetros definidos es alto. Esto puede llevar a
la falla por parte del planificador para resolver la tarea sin antes haber
tenido la posibilidad de realizar la búsqueda en el espacio de instancias,
incluso cuando en la práctica solo una pequeña fracción de ellas ocurren en los
planes del problema.
\citep{Gnad_Torralba_Dominguez_Areces_Bustos_2019}

Ahora bien, si se obtienen las acciones necesarias para confeccionar por lo
menos un plan, entonces el proceso de búsqueda encontraría alguna de tales
soluciones. Por ende, surge la siguiente pregunta, ¿Cómo determinamos que
acciones son relevantes para algún plan de tal manera que puedan ser incluidas
en el proceso de grounding?

Esta pregunta es la que nos llevó a considerar el uso de técnicas de
\emph{aprendizaje automático}. Los modelos de aprendizaje automático consisten
en aproximar una función a partir de datos de entrenamiento, es decir, ejemplos
a los cuales se conoce el valor de entrada y de salida de la función. La idea
principal se basó en encontrar una función que prediga la probabilidad de que
una acción sea relevante a partir de información del problema. Dado que las
tareas que nos interesan resolver son aquellas que no pueden ser groundeadas, es
necesario recurrir a problemas equivalentes pero más sencillos durante la
construcción del material de entrenamiento.

Otro inconveniente es decidir que información del problema se puede brindar al
modelo de aprendizaje automático de tal manera que identifique si una acción es
importante. Evidentemente, no puede ser el plan de la tarea, ya que para
aquellos problemas que fallan durante el proceso de grounding no se puede
encontrar el plan que lo resuelve. Debe ser una característica que brinde
información, aunque sea aproximada, de la estructura del plan real y que pueda
ser computada previamente al proceso de grounding. En \citep{hoffman-2001} se
estudia el uso de funciones heurísticas definidas a partir de \emph{planes
relajados} que permiten guiar el proceso de búsqueda de un plan. Si los planes
relajados son capaces de guiar el proceso de búsqueda, entonces también existe
una posibilidad de que pueda ser usado para guiar el proceso de grounding. Esta
relajación del plan real conocida como \emph{plan relajado} es la característica
principal de los modelos entrenados durante nuestros experimentos y que
analizaremos con más detalle durante el desarrollo de esta tesis.

Por otro lado, los modelos de aprendizaje automático dependen fuertemente de
como se representan los datos que uno tiene disponible \citep{Heaton-2016-AnEA}.
Para obtener un modelo de aprendizaje supervisado se necesita construir un
vector de \emph{features} que permita codificar nuestros datos, en particular,
un plan relajado y una acción. Una opción es proyectar los ejemplos a un espacio
vectorial a partir de una codificación del tipo \emph{one-hot}, donde enumeramos
los posibles esquemas de acción, y objetos de un problema para representar
numéricamente una acción y por consecuente una secuencia de ellas. Otra
posibilidad es utilizar el concepto de \emph{word embeddings}
\citep{Mikolov-2013, Pennington-Jeffrey-Socher-Richard-Manning-Christopher-2014,
Bojanowski-Grave-Joulin-Mikolov-2016} proveniente del procesamiento del lenguaje
natural. Estos tienen como objetivo proyectar palabras y oraciones a un espacio
$N$ dimensional que preserve su semántica, es decir, expresiones con un
significado similar, son dispuestas cerca en el espacio. La intuición principal
es obtener un modelo de lenguaje, pensando un plan como una oración, que
caracterice el lenguaje generado por los planes relajados y las acciones
instanciadas. 

En resumen, la hipótesis inicial de este trabajo es investigar distintas
codificaciones de nuestros datos que permitan al modelo de \emph{machine
learning} reconocer la relación entre los planes relajados, acciones, y planes
reales, de tal manera que guíen el proceso de \emph{grounding}.

\section{Trabajos relacionados}

En la literatura de planning se pueden encontrar numerosos avances que intentan
guiar el proceso de grounding efectuado por el planificador. Algunas se basan en
evitar instanciar acciones que no son alcanzables relajadamente desde el estado
inicial, tal es el caso del planificador Fast Downward \citep{Helmert-2011}
utilizado en competencias de planning. En \citep{Roger-SieversKatz-2018}
estudian nociones de simetría sobre la especificación de la tarea de planning
para evitar trabajo redundante. Otra opción es reducir el tamaño de las
interfaces de los esquemas de acción al dividirla en subpartes. De esta manera
la explosión exponencial de acciones groundeadas se disminuye drásticamente.
Esta técnica se denomina \emph{action schema splitting} y es desarrollada en
\citep{Areces_Bustos_Dominguez_Hoffmann_2014}. También existen métodos que
evitan el proceso de grounding completamente y realizan la búsqueda del plan a
partir de su especificación PDDL \citep{Penberthy-1992}.

En particular, esta tesis continua con la línea de investigación desarrollada en
\citep{Gnad_Torralba_Dominguez_Areces_Bustos_2019} donde también proponen guiar
el proceso de grounding por medio de aprendizaje automático. La diferencia
radica en las características usadas para entrenar los modelos, en lugar de
planes relajados y acciones, se codifica una acción por medio de reglas
relacionales que capturan propiedades significativas de una acción.

Salvo esta última heurística no se han visto muchos estudios sobre el uso de
técnicas de aprendizaje automático en el área de planning, lo cual es una fuerte
iniciativa para empezar a combinar estos dos campos.

\section{Estructura de la tesis}

Los capítulos \ref{ch:lit_planning} y \ref{ch:lit_ml} detallan los conceptos
fundamentales de planning y aprendizaje automático que se utilizaran para unir
estas dos áreas.

El capítulo \ref{ch:method} describe que problemas de planning utilizaremos para
entrenar los modelos de aprendizaje automático, junto a la exploración de los
datos, preprocesamiento, separáción en entrenamiento y test, y evaluación de
modelos. A su vez, se presentarán los 2 métodos principales de codificación de
planes relajados y acciones que trabajamos durante la tesis.

El capítulo \ref{ch:results} presenta los experimentos realizados, mostrando el
desempeño de varios modelos predictivos a partir de las codificaciones
propuestas en el capìtulo \ref{ch:lit_ml}. Además, se mencionan otros
experimentos que fueron parte del proceso científico, que a pesar no lograr un
resultado esperado, fueron de gran utilidad para reevaluar nuestros objetivos.

Por último, en el capítulo \ref{ch:con} se escriben las conclusiones de la tesis
junto a las líneas de trabajo a futuro.