\chapter{Experimentos y resultados}
\label{ch:results}

En este capítulo presentaremos los experimentos principales realizados a partir de lo desarrollado en el capítulo \ref{ch:method}. En particular, utilizaremos las 2 codificaciones (ad-hoc y por word embeddings) propuestas bajo los 3 clasificadores (regresión logistica, XGBoost, y perceptrón multicapa) presentados en los fundamentos teóricos con el fin de determinar aquella configuración (transformador + clasificador) que brinde los mejores resultados en el conjunto de test. Luego procederemos a comparar el desempeño de ambas codificaciones.

Para los mejores modelos, se calcularon los tiempos de predicción con el fin de determinar si son viables a ser utilizados por el planificador si se realizan por batches o por ejemplo.

Por último, se mencionan algunos otros experimentos los cuales se trabajaron durante la tesis pero no inc

\section{Modelo predictivo ad-hoc}
\label{exp:ad-hoc}

\subsection{Configuración del experimento}

Para este experimento utilizamos una codificación ad-hoc, usando como conjunto de entrenamiento ventanas de planes relajados y acciones. Las ventanas en particular fueron construidas con un tamaño y paso de $3$ siendo este el largo usual de los planes relajados cuyos problemas se les puede encontrar una solución óptima. El conjunto de entrenamiento fue dividido por esquemas de acción, entrenando un modelo para cada uno. Esto con el fin de capturar la información significativa de un solo esquema. Todos los modelos, aún así, predicen la probabilidad de una acción de pertenecer a un plan real dado una ventana del plan relajado. Por lo tanto los valores de dos modelos distintos aún son comparables.

Para el entrenamiento de los clasificadores, se realizó una búsqueda de hiper-parámetros cuya métrica a optimizar es la $F_{\beta}$ con $\beta = 2$ de manera de priorizar recall sobre precisión. En particular buscamos que el clasificador sea penalizado si no logra predecir todas las acciones relevantes, o si no logra filtrando una cantidad aceptable de acciones poco necesarias.

Para las evaluaciones, cada par de ventana de plan relajado y acción, es agrupado por plan relajado y acción de tal manera de obtener la probabilidad máxima. Es decir, ni bien tengamos una sospecha de que una acción es una instancia relevante, debería ser groundeada.

La grilla de parámetros a buscar por clasificador fue la siguiente:

\begin{conditions}
Nombre\ del\ modelo & \verb|Regresión logística| \\
penalty & \verb|[elasticnet]| \\
C & \verb|[1, 0.1, 0.01]| \\
class\_weight & \verb|[balanced]|  \\
solver & \verb|[saga]|  \\
max\_iter & \verb|[100 1000 10000]| \\
random\_state & \verb|[0]| \\
l1\_ratio & \verb|[0, 1, 0.5, 0.8, 0.2]|
\end{conditions}

\begin{conditions}
Nombre\ del\ modelo & \verb|XGBoost| \\
objective & \verb|[binary:logistic]| \\
n\_estimators & \verb|[500, 1000, 1500]| \\
gamma & \verb|[0.001, 1]| \\
max\_depth & \verb|[10, 20]| \\
alpha & \verb|[0.001, 1]| \\
lambda & \verb|[0.001, 1]| \\
booster & \verb|[gbtree]| \\
colsample\_bytree & \verb|[1]| \\
subsample & \verb|[0.5, 1]| \\
eval\_metric & \verb|[logloss]| \\
use\_label\_encoder & \verb|[false]| \\
random\_state & \verb|[0]|
\end{conditions}

\begin{conditions}
Nombre\ del\ modelo & \verb|PytorchNN| \\
h\_size & \verb|[32, 64]| \\
n\_layers & \verb|[1, 2, 4, 8, 16]| \\
bn\_bool & \verb|[True, False]| \\
p & \verb|[0, 0.1]| \\
epochs & \verb|[20, 40]| \\
batch\_size & \verb|[32]| \\
balanced & \verb|[True]| \\
lr & \verb|[0.001]| \\
weight\_decay & \verb|[0]| \\
\end{conditions}

En el caso de la regresión logística, el parámetro $penalty$ permite realizar variaciones en la regularización de la función de costo en combinación con $l1\_ratio$. XGBoost requiere que se le especifiquen la cantidad de árboles a ensamblar con $n\_estimators$, la fuerza en del parámetro de regularización $gamma$ o la profundidad del árbol $max\_depth$. A la red neuronal se agregaron el número de neuronas para todas las capas $h\_size$, la cantidad de capas ocultas $n\_layers$, si hay normalización como primera capa $bn\_bool$, la probabilidad de eliminar neuronas aleatoriamente $p$, entre otros.

La cantidad de parámetros a buscar es igual al producto cartesiano de cada una de las listas de los parámetros. Por ejemplo para el caso de la regresión logística, se realizan un total de $3 \times 3 \times 5 = 45$ búsquedas.

\subsection{Resultados}

\section{Modelos predictivo por word embeddings}
\label{exp:wb}

\subsection{Configuración del experimento}

Como contraparte del experimento anterior usaremos la codificación por word embeddings, bajo el mismo conjunto de entrenamientos y construcción de ventanas, con la salvedad de ser codificados a partir del modelo de lenguaje de FastText, entrenado con oraciones provenientes de planes relajados. El modelo de lenguaje es un modelo Skipgram con una cantidad de $100$ épocas, un tamaño de ventana de contexto de $3$, y un vector de salida de dimensión $30$. Se hicieron pruebas sobre otras configuraciones de parámetros pero el comportamiento que buscábamos que el modelo de lenguaje aprendiese ya era obtenido bajo esta configuración.

Los clasificadores y grillas de búsqueda de parámetros utilizadas fueron las mismos que el modelo predictivo ad-hoc.

\subsection{Resultados}

\section{Comparación de mejores modelos}
\label{results:comparison}

\section{Tiempos de predicción}
\label{exp:time}

Para un nuevo ejemplo no visto se debe realizar el proceso completo creación de ventanas, codificación, predicción por parte del clasificador, y posterior agrupamiento de ventanas para obtener la máxima prioridad. Al incluir los modelos predictivos en el proceso de grounding heurístico el tiempo necesario para realizar todas las etapas y obtener el valor de salida del modelo predictivo es importante durante el proceso de grounding heurístico ya que los planificadores deben encontrar la solución a la tarea asignada de acuerdo a un tiempo límite, si este es excedido, ocurre una falla por parte del planificador. Esto motivo la medición del tiempo de respuesta para los modelos predictivos comparados en la sección \ref{results:comparison}.

Actualmente la implementación de grounding heurístico en Fast Downward, son realizadas a nivel de ejemplo. Por lo que la unidad de medida utilizada fueron \emph{ns/ejemplo}, no obstante también se probaron realizar las predicciones a nivel de batch con el de determinar que tan prometedor es incluir este cambio en el algoritmo de grounding heurístico.

\subsection{Predicciones por batch}

\subsection{Predicciones por acción}

\section{Otros experimentos}

Los experimentos presentados en las secciones \ref{exp:ad-hoc}, \ref{exp:wb}, y \ref{exp:time} fueron aquellos principales y los que nos enfocamos durante la tesis. No obstante, se intentaron otras vías de análisis que llevaron a 4 experimentos con el fin de lograr aquel modelo que nos permita guiar el proceso de grounding. A pesar de no lograr resultados concretos fueron parte importante del trabajo y otorgaron conocimiento invaluable para involucrarse más en el dominio del problema.

\subsection{Modelos End-to-end}

End-to-end (E2E) models refieren a sistemas complejos representados por un único modelo neuronal profundo ensamblando las capas de preprocesamiento y como capas intermedias del modelo. En particular, este tipo de pruebas se realizaron en una etapa temprana de la tesis donde la idea de generar ventanas de planes relajados aún no se había investigado. En particular se experimentaron con modelos E2E de FastText donde agrega una capa neuronal más al modelo de embeddings para que sean utilizados en clasificación.
No obstante se optó por descontinuar estos experimentos al comenzar ya que fueron experimentos prototipos donde se buscaba verificar la factibilidad del uso de word embeddings en grounding heurístico.

\subsection{El problema de inclusión sobre planes relajados}

Otra estrategía que utilizamos durante el análisis en la generación de ventanas de planes relajados, fue plantear el problema de clasificación binaria como uno multiclase. En lugar de solo 2 clases, manteníamos 4 que representaban la noción de si una acción estaba incluido en el plan relajado y si eran parte de los good operators del problema. Es decir, una ventana de plan relajado $w$ y acción $a$ es etiquetada como:

\begin{itemize}
    \item 0: Si $a$ no es good operator y no pertenece a $w$.
    \item 1: Si $a$ no es good operator y pertenece a $w$.
    \item 2: Si $a$ es good operator y no pertenece a $w$.
    \item 3: Si $a$ es good operator y pertenece a $w$.
\end{itemize}

Luego al agrupar por ventanas y acción, consideramos como predicción final la clase $3$ si al menos una de las ventanas predijo $3$. Caso contrario si para alguna ventana la predicción fue $2$ predicción del agrupamiento es $2$. Y así sucesivamente hasta la clase $0$.

\subsection{Mayorización}

La repetición de ejemplos con etiquetas diferentes puede dificultar el aprendizaje de un modelo, si no son preprocesadas con alguna técnica de mayorización. Es decir, de entre todas las repeticiones del mismo ejemplo pero con distintas clases, mantener una sola replica preservando la etiqueta que haya ocurrido en mayor cantidad. Esta técnica fue aplicada para la codificación por word embeddings, donde una hipótesis para mejorar la separación de los ejemplos de entrenamiento fue asignar la etiqueta mayoritaria para todo los vector de dimensión $D$ (plan relajado, acción) que estén cerca en un rango en $\mathbb{R}^{D}$.

\subsection{Orden de ventanas como características}

Por último otra implementación que se agregó al sistema y que es un patrón configurable de las etapas de ejecución es la posibilidad de mantener el orden en que ocurren las ventanas. Es decir, se tiene

\begin{table}[h!]
\centering
\scalebox{0.9}{
 \begin{tabular}{||c | c | c | c||} 
 \hline
 Plan relajado & Orden de ventana & Acción & Etiqueta \\ [0.5ex] 
 \hline\hline
 %(take_image satellite0 planet5 instrument1 image1)
 {}[] & 1 &{}[] & 1 \\
 {}[] & 2 &{}[] & 1 \\
 {}[] & 3 &{}[] & 1  \\
 ... & ... & ... & ...\\ [1ex] 
 \hline
 \end{tabular}}
 \caption{Ejemplos etiquetados a partir de un plan relajado y una acción}
 \label{tb:matrix_shape}
\end{table}

El objetivo de este agregado es evitar perder la información del orden durante la separación y se buscaba analizar si es un factor relevante para el entrenamiento y evaluación.