\chapter{Experimentos y resultados}
\label{ch:results}

En este capítulo presentaremos los experimentos principales realizados a partir
de lo desarrollado en el capítulo \ref{ch:method}. Entrenaremos 2 grupos de
modelos predictivos. Un grupo con una codificación ad-hoc, y otro grupo con una
codificación por word embeddings. Los vectores de características tendrán como
información una ventana del plan relajado y una acción. Se destacarán aquellos
modelos que presenten mejores resultados en validación cruzada y sobre ejemplos
del conjunto de test.

Por otro lado, se entrenarán los 3 algoritmos de clasificación vistos en el
capítulo \ref{ch:lit_ml}, \emph{XGBoost}, \emph{regresión logística}, y
\emph{perceptrón multicapa}. Los conjuntos de entrenamiento y de test son
divididos por esquemas de acción, entrenando un modelo por cada uno. Esto con el
fin de capturar la información significativa de un solo esquema por modelo. Por
lo tanto, la estructura de nuestros experimentos para ambos grupos es la
siguiente:

\begin{itemize}
    \item Codificación ad-hoc o por word embeddings:
    \begin{itemize}
        \item Regresión logistica:
        \begin{itemize}
            \item \verb|take_image|
            \item \verb|turn_to|
            \item \verb|calibrate|
            \item \verb|switch_on|
            \item \verb|switch_off|
        \end{itemize}
        \item XGBoost:
        \begin{itemize}
            \item \verb|take_image|
            \item \verb|turn_to|
            \item \verb|calibrate|
            \item \verb|switch_on|
            \item \verb|switch_off|
        \end{itemize}
        \item Redes neuronales:
        \begin{itemize}
            \item \verb|take_image|
            \item \verb|turn_to|
            \item \verb|calibrate|
            \item \verb|switch_on|
            \item \verb|switch_off|
        \end{itemize}
    \end{itemize}
\end{itemize}

Por último, mencionaremos otros experimentos que se trabajaron durante la tesis
y la importancia que tuvieron para guiar futuros experimentos.

\section{Modelos predictivos por word embeddings}
\label{exp:ad-hoc}

\subsection{Configuración del experimento}

En primer lugar, se necesitó asignar la configuración para la construcción de
las ventanas y planes relajados.  Observamos que por lo general los planes
relajados del conjunto de entrenamiento tienen entre $3$ y $10$ acciones.
Nuestro algoritmo debe ser capaz de generalizar para ejemplos de entrenamientos
no antes visto, por lo que el preprocesamiento que realicemos sobre estos datos
debe ser orientado a reducir las discrepancias entre un ejemplo nuevo y los que
fueron utilizados en la etapa de entrenamiento. Como el largo de los planes
relajados de los problemas de test es por encima de los cientos de acciones,
generamos ventanas que aproximen en tamaño a los planes relajados de los
problemas de entrenamiento. Es por ello, que optamos por un paso y tamaño de
ventana de $3$.

Para el entrenamiento de los clasificadores, se realizó una búsqueda de
hiperparámetros cuya métrica a optimizar es $H_{\beta}$ con $\beta = 1.5$. Dado
que en nuestro problema es más importante predecir correctamente todas las
acciones relevantes, optamos por priorizar la taza de verdaderos positivos sobre
la taza de verdaderos negativos. Es decir, buscamos que el clasificador sea
penalizado si no logra predecir todas las acciones relevantes para obtener un
plan, y si no logra filtrar una cantidad aceptable de acciones no relevantes.

Recordemos que para evaluar los modelos, generamos las predicciones a nivel de
ventana de plan relajado y acción. Pero, buscamos predecir si una acción
es relevante dada la información del plan relajado completo, por lo que es
necesario agrupar las predicciones que cada ventana hizo sobre esa acción.
Por ejemplo, supongamos que tenemos $M$ ventanas de un plan relajado $\vec{a}$
de una tarea $\Pi$ y se busca determinar la probabilidad de una acción $a'$ dado
$\vec{a}$. El modelo de aprendizaje automático propuesto realiza $M$
predicciones para $a'$ dado las $M$ ventanas de $\vec{a}$ donde cada estimación
es una probabilidad. En lugar de evaluar el modelo con las $M$ predicciones, las
agrupamos para obtener solo una. Para este experimento, seleccionamos el máximo
de las $M$ probabilidades. Notar que bajo esta decisión, una probabilidad baja
significa que para todas las ventanas del plan relajado, el planificador le
asignó una baja probabilidad a $a'$, mientras que una probabilidad alta requiere
que por lo menos una ventana del plan relajado haya provisto la información
necesaria para considerar relevante a $a'$.

Por último, los algoritmos presentados en el capítulo \ref{ch:lit_ml}
implementan una solución genérica de los métodos de aprendizaje. Por lo que se
requiere especificar como van a estar configurados antes de empezar el proceso
de entrenamiento. La siguiente lista de parámetros muestra aquellos que fueron
utilizados para cada algoritmo en este experimento:

\begin{conditions}
\emph{Nombre\ del\ modelo} & \verb|Regresión logística| \\
\emph{penalty} & \verb|[elasticnet]| \\
\emph{C} & \verb|[1, 0.1, 0.01]| \\
\emph{class\_weight} & \verb|[balanced]|  \\
\emph{solver} & \verb|[saga]|  \\
\emph{max\_iter} & \verb|[1000, 10000]| \\
\emph{random\_state} & \verb|[0]| \\
\emph{l1\_ratio} & \verb|[0, 1]|
\end{conditions}

\begin{conditions}
\emph{Nombre\ del\ modelo} & \verb|XGBoost| \\
\emph{objective} & \verb|[binary:logistic]| \\
\emph{n\_estimators} & \verb|[500, 1000]| \\
\emph{gamma} & \verb|[0.001, 1]| \\
\emph{max\_depth} & \verb|[10, 20]| \\
\emph{alpha} & \verb|[0.001, 1]| \\
\emph{lambda} & \verb|[0.001, 1]| \\
\emph{booster} & \verb|[gbtree]| \\
\emph{colsample\_bytree} & \verb|[1]| \\
\emph{subsample} & \verb|[0.5]| \\
\emph{eval\_metric} & \verb|[logloss]| \\
\emph{use\_label\_encoder} & \verb|[false]| \\
\emph{random\_state} & \verb|[0]|
\end{conditions}

\begin{conditions}
\emph{Nombre\ del\ modelo} & \verb|PytorchNN| \\
\emph{h\_size} & \verb|[32, 64]| \\
\emph{n\_layers} & \verb|[2, 4, 8, 16]| \\
\emph{bn\_bool} & \verb|[False]| \\
\emph{p} & \verb|[0, 0.1]| \\
\emph{epochs} & \verb|[20]| \\
\emph{batch\_size} & \verb|[32]| \\
\emph{balanced} & \verb|[True]| \\
\emph{lr} & \verb|[0.001]| \\
\end{conditions}

Estos parámetros corresponden con la interfaz provista por las librerías de
\emph{Scikit-learn} y \emph{Pytorch} que implementan los algoritmos de
aprendizaje. Cada parámetro muestra una lista de uno o más valores donde cada
elemento representa una posible asignación de ese parámetro. La cantidad de
configuraciones posibles de un modelo es igual al producto cartesiano de cada
una de las listas de los parámetros de un modelo. Por ejemplo para el caso de la
regresión logística, los parámetros \emph{C}, \emph{max\_iter}, y
\emph{l1\_ratio} tienen 3, 2, y 2 asignaciones respectivamente, el resto de
parámetros solo tiene una. Por lo tanto, hay un total de $3 \times 2 \times 2 =
12$ configuraciones del modelo.

Los parámetros que seleccionamos siempre buscaban plantear variantes en la
función de costo a optimizar, el tipo de optimizador, y métodos para evitar el
sobreajuste. En particular, seguimos como guía valores comunes que la comunidad
de aprendizaje automático suele utilizar para estos modelos,  la experiencia
transmitida por el ´´boca a boca´´, y conocimientos tanto del área de planning
como del funcionamiento interno de los modelos utilizados. 

En el caso de la regresión logística, los parámetros \emph{penalty},
\emph{l1\_ratio}, y \emph{C} permiten realizar variaciones en la regularización
de la función de costo, evitando que la norma del vector de pesos del modelo
crezca demasiado por sobreajuste. \emph{solver} indica el método de optimización
de la función de costo. \emph{max\_iter} es el número de iteraciones que
requiere el algoritmo para converger. Por último, \emph{class\_weight} permite
configurar el modelo de tal manera que balancee la cantidad de ejemplares
positivos y negativos del material de entrenamiento. Este último es importante
para nosotros, ya que nuestro conjunto de entrenamiento está desbalanceado,
teniendo una mayor cantidad de bad operators que de good operators por problema.

XGBoost requiere que se le especifiquen la cantidad de árboles a ensamblar con
\emph{n\_estimators}, la fuerza del parámetro de regularización \emph{gamma}, y
la profundidad máxima de los árboles \emph{max\_depth}. \emph{objetive} indica
la función objetivo a optimizar, en este caso la misma función de costo que una
regresión logística. \emph{booster} permite seleccionar variantes del método
iterativo de boosting explicado en el capítulo \ref{alg:xgboost}. Por último
\emph{colsample\_bytree} y \emph{subsample} permiten tomar una muestra con
reposición de las filas o columnas en la confección de un árbol en el ensemble
con el propósito de reducir el sobreajuste.

La red neuronal necesita del número de neuronas para todas las capas
\emph{h\_size}, la cantidad de capas ocultas \emph{n\_layers}, si los vectores
de entrada son normalizados \emph{bn\_bool}, y la probabilidad \emph{p} de
apagar momentáneamente neuronas de la red de manera aleatoria.

Por cada posible asignación obtenemos aquella que mejor se comporte con el
conjunto de test. Recordemos que nuestro objetivo es encontrar modelos que se
puedan utilizar para algún esquema de acción. De un total de 5 esquemas de
acción en el dominio \emph{Satellite}, el mejor caso sería encontrar 5 modelos
que den buenos resultados en esos esquemas.

\subsection{Resultados: take\_image}

Empecemos por el esquema de acción \verb|take_image| con el cual obtuvimos
mejores resultados. De los 3 modelos regresión logística (LGR), xgboost (XGB), y
redes neuronales (NN), LGR resultó el de mejor comportamiento.

\begin{figure}[t!]
    \centering
    \includegraphics[width=\linewidth]{figures/results/word_embeddings/lgr/take_image/lgr_wb_take_image.png}
    \caption{Distribución de predicciones en validación cruzada para el modelo de LGR con word embeddings.}
    \label{fig:takeimage-bestmodel-distplot}
\end{figure}

\subsubsection{Performance en validación cruzada}

La figura \ref{fig:takeimage-bestmodel-distplot} muestra la distribución de las
predicciones en validación cruzada para la mejor configuración de parámetros de
LGR.


\begin{figure}[b!]
    \minipage{0.50\textwidth}
    \includegraphics[width=\linewidth]{figures/results/word_embeddings/lgr/take_image/lgr_set_1_confusion_matrix_percent.png}
    \endminipage
    \minipage{0.50\textwidth}
    \includegraphics[width=\linewidth]{figures/results/word_embeddings/lgr/take_image/lgr_set_2_confusion_matrix_percent.png}
    \endminipage
        
    \minipage{0.50\textwidth}%
    \includegraphics[width=\linewidth]{figures/results/word_embeddings/lgr/take_image/lgr_set_3_confusion_matrix_percent.png}
    \endminipage
    \minipage{0.50\textwidth}
    \includegraphics[width=\linewidth]{figures/results/word_embeddings/lgr/take_image/lgr_set_4_confusion_matrix_percent.png}
    \endminipage

    \minipage{0.50\textwidth}
      \includegraphics[width=\linewidth]{figures/results/word_embeddings/lgr/take_image/lgr_set_5_confusion_matrix_percent.png}
    \endminipage
    \caption{Matrices de confusión en validación cruzada para el modelo de LGR con word embeddings.}
    \label{fig:takeimage-bestmodel-cm}
\end{figure}

Para cada partición, se muestran dos histogramas independientes, el de la clase
positiva, y el de la clase negativa. Cada punto en el gráfico representa la
probabilidad de una acción dado su plan relajado (completo). En ambos
histogramas se genera una cantidad $N$ de bins equidistantes en el rango
$[0;1]$. Luego, para cada bin $b$, se muestra la cantidad de acciones que
recibieron una probabilidad contenida en $b$ divido el tamaño de la clase a la
que pertenecen.

Para los histogramas de la clase positiva, observamos que las acciones
relevantes (good operators) se agrupan en los bins con probabilidades entre
$r=[0,6; 1]$. Cada bin contiene entre el 2\% al 7\% de las acciones. Si sumamos
los porcentajes de cada uno de los bins en $r$, tendremos que más de la mitad de
las acciones se encuentran en $r$.

Por otro lado, los histogramas de la clase negativa, muestran que más de la
mitad de las acciones no relevantes (bad operators) se agrupan en los bins con
probabilidades entre $[0;0.4]$.

Desde el punto de vista de grounding heurístico este es el comportamiento que
buscamos. El algoritmo almacenará en una cola de prioridades acciones tanto
relevantes como no relevantes con una probabilidad asociada, dándole prioridad a
las que tienen una mayor probabilidad. Si el modelo asigna a las acciones
relevantes una alta probabilidad entonces el proceso de grounding heurístico les
dará prioridad para su instanciación.

Notar que el objetivo de utilizar validación cruzada es variar el conjunto de
entrenamiento con el fin de determinar si el modelo de LGR es robusto ante
cambios, lo cual podemos decir que indudablemente fue este el caso en las 5
particiones.

Si observamos la matriz de confusión del modelo por cada partición dada en la
figura \ref{fig:takeimage-bestmodel-cm}, podemos ver que en cada uno, más del
90\% de las acciones positivas se predicen como positivas, y más del 63\% de las
negativas se predicen como negativas. La función de decisión se obtiene a partir
de optimizar $H_{1.5}$. Es decir, se computa $H_{1.5}$ para distintas funciones
de decisión con umbral en el intervalo [0, 1] y utilizamos aquel que maximice
$H_{1.5}$. 

\begin{table}[h!]
    \centering
    \scalebox{1}{
     \begin{tabular}{|c || c | c | c | c | c | c |} 
     \hline
      Clase & Fold & Precisión & Recall & $H_{1.5}$ & $F_{1.5}$ & Umbral de
      decisión \\
     \hline
     Relevante &  1 & 0.14 & 0.91 & 0.804 & 0.338 & 0.41\\
     No relevante & 1 & 0.99 & 0.64 & 0.703 & 0.7181 & 0.41 \\
     \hline
     Relevante & 2 & 0.095 & 0.93 & 0.822 & 0.251 & 0.42 \\
     No relevante & 2 & 1 & 0.66 & 0.720 & 0.7371 & 0.42 \\
     \hline
     Relevante & 3 & 0.14 & 0.93 & 0.83 & 0.340 & 0.38 \\
     No relevante & 3 & 0.99 & 0.67 & 0.7295 & 0.744 & 0.38\\
     \hline
     Relevante & 4 & 0.12 & 0.9 & 0.797 & 0.300 & 0.43\\
     No relevante & 4 & 0.99 & 0.63 & 0.6944 & 0.709 & 0.43\\
     \hline
     Relevante & 5 & 0.12 & 0.93 & 0.821 & 0.3022 & 0.44 \\
     No relevante & 5 & 0.99 & 0.65 & 0.7147 & 0.7268 & 0.44 \\
     \hline
     \end{tabular}}
     \caption{Métricas en validación cruzada del modelo LGR con word embeddings.}
     \label{results:lgr-wb-takeimage-tb}
\end{table}

\subsubsection{Performance en test}

Los resultados anteriores fueron sobre 5 particiones del conjunto de
entrenamiento donde una parte efectivamente se utilizaba para entrenar el modelo
y otra para su evaluación. Sin embargo, lo que buscamos es que lo aprendido se
logre generalizar a problemas no instanciables. Por lo tanto, la evaluación
final la realizamos sobre el conjunto de test.

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.7\linewidth]{figures/results/word_embeddings/lgr/take_image/lgr_wb_take_image_test.png}
    \caption{Distribución de predicciones sobre el conjunto de test del modelo de LGR con word embeddings.}
    \label{fig:takeimage-bestmodel-distplot-test}
\end{figure}

\begin{figure}[t!]
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width=0.7\linewidth]{figures/results/word_embeddings/lgr/take_image/lgr_set_6_confusion_matrix_percent.png}
        \caption{Matriz normalizada por clase}
        \label{fig:takeimage-bestmodel-cm-test}
    \end{subfigure}
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width=0.7\linewidth]{figures/results/word_embeddings/lgr/take_image/lgr_set_6_confusion_matrix_raw.png}
        \caption{Matriz sin normalización}
        \label{fig:takeimage-bestmodel-cm-raw-test}
    \end{subfigure}
    \caption{Matrices de confusión sobre el conjunto de test del modelo de LGR con word embeddings.}
\end{figure}

La figura \ref{fig:takeimage-bestmodel-distplot-test} muestra nuevamente un
histograma de la probabilidad de una acción dado su plan relajado. Para el caso
de las acciones relevantes, se sigue manteniendo el comportamiento que vimos en
validación cruzada lo cual es un buen indicio, ya que estarán en las primeras
posiciones en la cola de prioridades en grounding heurístico. Sin embargo, si
observamos el histograma de acciones no relevantes, se tiene que ahora a una
gran parte de ellas se le asigna una alta probabilidad. Estas acciones también
serían ubicadas al comienzo de la cola de prioridades y, por lo tanto,
instanciadas. Si observamos la matriz de confusión en la figura
\ref{fig:takeimage-bestmodel-cm-test}, la proporción de acciones relevantes se
mantiene en un 91\%, mientras que esta vez solo un 33\% de las negativas se
predicen como negativas. Cabe recalcar que esta vez, el umbral de decisión en
test es el promedio de los umbrales obtenidos en validación cruzada. El objetivo
era aprender un umbral que sea lo más óptimo para predecir nuevos ejemplos,
utilizando únicamente información de los datos de entrenamiento. Por lo que se
usó el promedio de los umbrales de validación cruzada siendo este un valor
que toma en cuenta los umbrales de las 5 particiones. Podríamos haber
empleado un umbral de decisión a partir de las etiquetas de test, pero
tal predicción representaría la performance máxima o ideal que podríamos obtener
en test, y no la que realmente estamos obteniendo con información del conjunto
de entrenamiento.

Observemos la matriz de confusión de la figura
\ref{fig:takeimage-bestmodel-cm-raw-test} del modelo LGR, pero esta vez sin
normalizar por porcentajes. Se puede ver que LGR tiende a predecir ligeramente
sobre la clase positiva, pero además es la mayoritaria en test para este
esquema. Esto sucede debido a como se generan los bad operators en los problemas
de test. Recordemos que estos no pudieron obtenerse a través de Fast Downward,
por lo se generó una muestra aleatoria usando grounding cartesiano pero
respetando los tipos de las interfaces. Como solo se pudieron generar una
cantidad de 5000 bad operators por problema, y los planes en los problemas de
test son de mayor tamaño que los de entrenamiento, surgió este desbalance hacia
la clase positiva. No obstante, en una situación real, la cantidad de bad
operators sería nuevamente superior a la de good operators. Otro aspecto
importante sobre la generación de los bad operators es que podrían no ser
alcanzables relajadamente y, por ende, tener una distribución distinta a la
que tenemos en el conjunto de entrenamiento siendo una de las posibles causas
del desempeño de LGR para la clase negativa. Es decir, LGR fue entrenado para
predecir, sobre acciones alcanzables relajadamente, pero lo estamos evaluando
sobre bad operators que no lo son.

Por último, en el cuadro \ref{results:lgr-wb-calibrate} se puede ver que
precision y recall sobre la clase positiva es de 0.823, y 0.912,
respectivamente. Si calculamos la métrica $F_{1.5}$ priorizando recall,
obtendriamos una performance de 0.8826 para LGR. Sin embargo, no es un buen
indicio de la correctitud del modelo en la clase negativa. En contraparte, si en
lugar de considerar $F_{1.5}$ utilizamos $H_{1.5}$ la performance es de 0.589
debido a que esta métrica penaliza si se tiene un baja en la taza de verdaderos
negativos.


\begin{table}[t!]
\centering
\scalebox{1}{
 \begin{tabular}{|c || c | c | c | c | c | c |} 
 \hline
  Clase & Precisión & Recall & $H_{1.5}$ & $F_{1.5}$ & Umbral de decisión \\
 \hline
 Relevante & 0.823 & 0.912 & 0.589 & 0.8826 & 0.416 \\
 No relevante & 0.52 & 0.33 & 0.4081 & 0.3717 & 0.416 \\
 \hline
 \end{tabular}}
 \caption{Métricas sobre el conjunto de test del modelo de LGR con word embeddings.}
 \label{results:lgr-wb-calibrate}
\end{table}

\section{Modelos predictivos ad-hoc}
\label{exp:wb}

\subsection{Configuración del experimento}

Para esta sección usaremos la codificación ad-hoc, bajo el mismo conjunto de
entrenamientos, construcción de ventanas, y configuraciones de búsqueda de los
modelos.

Describiremos el mejor modelo que obtuvimos con la codificación ad-hoc sobre un
esquema de acción distinto. En particular, el esquema \emph{calibrate} y el
perceptrón multicapa como modelo de aprendizaje.

\subsection{Resultados}

\subsubsection{Performance en validación cruzada}

La figura \ref{fig:calibrate-bestmodel-adhoc} muestra la distribución de las
predicciones en validación cruzada para la mejor configuración de parámetros de
NN. Si observamos los histogramas de la clase positiva, tenemos que
aproximadamente el 90\% de las acciones etiquetadas como positivas se agrupan en
el intervalo $r = [0.8; 1]$ mientras que de las negativas solo un 10\% al 20\%
se encuentra en $r$. Además, la mayoría de acciones negativas tienen
probabilidades en el rango del $[0;0.4]$ lo cual nuevamente estamos ante un muy
buen desempeño en validación cruzada en términos de grounding heurístico.

\begin{figure}[b!]
    \centering
    \includegraphics[width=\linewidth]{figures/results/ad-hoc/nn/calibrate/nn_adhoc_calibrate.png}
    \caption{Distribución de predicciones en validación cruzada sobre el modelo NN ad-hoc.}
    \label{fig:calibrate-bestmodel-adhoc}
\end{figure}

\begin{table}[h!]
    \centering
    \scalebox{1}{
     \begin{tabular}{|c || c | c | c | c | c | c |} 
     \hline
      Clase & Fold & Precisión & Recall & $H_{1.5}$ & $F_{1.5}$ & Umbral de
      decisión \\
     \hline
     Relevante &  1 & 0.31 & 0.85 & 0.798 & 0.5534 & 0.7\\
     No relevante & 1 & 0.97 & 0.71 & 0.74533 & 0.7738 & 0.7 \\
     \hline
     Relevante & 2 & 0.26 & 0.87 & 0.8 & 0.50525 & 0.77 \\
     No relevante & 2 & 0.98 & 0.68 & 0.7307 & 0.7507 & 0.77 \\
     \hline
     Relevante & 3 & 0.3 & 0.9 & 0.793 & 0.55714 & 0.72 \\
     No relevante & 3 & 0.97 & 0.63 & 0.6920 & 0.70616 & 0.72\\
     \hline
     Relevante & 4 & 0.31 & 0.86 & 0.803 & 0.5563& 0.75\\
     No relevante & 4 & 0.97 & 0.7 & 0.7430 & 0.76557 & 0.75\\
     \hline
     Relevante & 5 & 0.26 & 0.87 & 0.811  & 0.50526 & 0.57 \\
     No relevante & 5 & 0.98 & 0.7 & 0.7446 & 0.76747 & 0.57 \\
     \hline
     \end{tabular}}
     \caption{Métricas sobre el conjunto de test del modelo NN ad-hoc.}
     \label{results:nn-adhoc-calibrate}
\end{table}

El cuadro \ref{results:nn-adhoc-calibrate} muestra los resultados de predicción
por cada fold. Notar como el umbral de decisión optimizado por $H_{1.5}$ llegó a
alcanzar hasta un valor de 0.77 en el segundo fold. Aún para este valor de
umbral, los resultados en \emph{precision} no fueron muy altos para la clase
positiva. Recordemos que \emph{precision} en clase positiva penaliza los falsos
positivos (FPs). Observando el gráfico de distribuciones, el umbral estaría
separando adecuadamente las clases relevantes de las irrelevantes por lo cual no
se logra observar el porqué de estos resultados en \emph{precision} con este
gráfico.

Sin embargo, si en lugar de considerar las distribuciones revisamos las matrices
de confusión sin normalizar (Figura \ref{fig:calibrate-bestmodel-cm}),
observamos que los datos se encuentran desbalanceados para la clase 0.
Asemejándose a lo que usualmente ocurre con los problemas de planning donde los
good operators suelen ser menor en cantidad a los bad operators. En particular,
esto puede ser un problema para \emph{precision} dado que penaliza por la
cantidad de FPs. Por ejemplo, si observamos el primer fold de la validación
cruzada, se logra predecir correctamente por encima del 70\% de las acciones no
relevantes. Sin embargo, esto es relativo a la cantidad de acciones que tengamos
de la clase 0. Si tenemos en cuenta la fórmula de \emph{precision}:

\begin{align*}
    precision = \frac{TP}{TP + FP}
\end{align*}

Se logra observar que al depender de los FPs, entonces también depende de la
cantidad de desbalance que tenga el conjunto de datos. De hecho, si se
incrementa la cantidad de bad operators, pero las proporciones 70-30\% se
mantienen, la métrica disminuiría. Sin embargo, en términos de grounding
heurístico el modelo seguiría desempeñándose correctamente.

\begin{figure}[h!]
    \minipage{0.50\textwidth}
    \includegraphics[width=\linewidth]{figures/results/ad-hoc/nn/calibrate/2021-12-06_17.03.17.314982_set_1_confusion_matrix_raw.png}
    \endminipage
    \minipage{0.50\textwidth}
    \includegraphics[width=\linewidth]{figures/results/ad-hoc/nn/calibrate/2021-12-06_17.03.17.314982_set_2_confusion_matrix_raw.png}
    \endminipage
        
    \minipage{0.50\textwidth}%
    \includegraphics[width=\linewidth]{figures/results/ad-hoc/nn/calibrate/2021-12-06_17.03.17.314982_set_3_confusion_matrix_raw.png}
    \endminipage
    \minipage{0.50\textwidth}
    \includegraphics[width=\linewidth]{figures/results/ad-hoc/nn/calibrate/2021-12-06_17.03.17.314982_set_4_confusion_matrix_raw.png}
    \endminipage

    \minipage{0.50\textwidth}
    \includegraphics[width=\linewidth]{figures/results/ad-hoc/nn/calibrate/2021-12-06_17.03.17.314982_set_5_confusion_matrix_raw.png}
    \endminipage
    \caption{Matrices de confusión en validación cruzada para el modelo NN ad-hoc.}
    \label{fig:calibrate-bestmodel-cm}
\end{figure}

\subsubsection{Performance en test}


Nuevamente, lo que buscamos es que este modelo logre generalizar a problemas no
instanciables. La figura \ref{fig:calibrate-bestmoodel-adhoc-test-dist} muestra como
se distribuyen las probabilidades que el modelo asigna a las acciones partícipes
del conjunto de test. Se puede observar un comportamiento muy distinto al que
ocurrió en validación cruzada. El umbral de predicción promedio obtenido en
validación cruzada es de 0.702. Bajo ese umbral, el modelo predice que todas las
acciones son irrelevantes obteniendo una performance prácticamente nula. Por lo
que a primera impresión parecería que no es un modelo que podamos utilizar en
grounding heurístico. De hecho, un resultado como este para un problema clásico
de aprendizaje automático llevaría a descartar la solución y probar con otra
configuración. No obstante, en el contexto de grounding heurístico, buscamos que
las acciones relevantes para encontrar un plan tengan una probabilidad superior
a las que no lo son. Sin importar en que parte del intervalo $[0;1]$ se asignen
las probabilidades. Mientras se respete el orden que necesitamos para ubicar las
acciones en la cola de prioridades, entonces podemos considerarlo como un buen
modelo. Es por eso la razón por la que el umbral de decisión tampoco se mantiene
fijo, y varía de acuerdo a $H_{\beta}$. Para este problema el umbral es una
manera de cuantificar esta idea más cualitativa que buscamos en grounding
heurístico, pero que es determinante en la elección del modelo de aprendizaje.

Por ejemplo, para un umbral de 0.1, podemos ver que el modelo se comporta de
manera similar al de \emph{take\_image} como muestra la figura
\ref{fig:calibrate-bestmoodel-adhoc-test-cm}.

\begin{figure}[h!]
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width=0.7\linewidth]{figures/results/ad-hoc/nn/calibrate/nn_adhoc_calibrate_test.png}
        \caption{Distribución de predicciones}
        \label{fig:calibrate-bestmoodel-adhoc-test-dist}
    \end{subfigure}
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width=0.7\linewidth]{figures/results/ad-hoc/nn/calibrate/NN_cm_test.png}
        \caption{Matriz de confusión}
        \label{fig:calibrate-bestmoodel-adhoc-test-cm}
    \end{subfigure}
    \caption{Resultados en el conjunto de test para el modelo NN ad-hoc.}
\end{figure}

\section{Otros experimentos}

Los experimentos presentados en las secciones \ref{exp:ad-hoc}, \ref{exp:wb},
fueron el principal eje de la tesis. No obstante, se intentaron otras vías de
análisis que llevaron a muchos más experimentos con el fin de lograr aquel
modelo que nos permita guiar el proceso de grounding. A pesar de no lograr
resultados concretos fueron parte importante del trabajo y otorgaron
conocimiento invaluable para involucrarse más en el dominio del problema.
En esta sección mencionaremos algunos de ellos.

\subsection{Modelos end-to-end}

Los modelos End-to-end (E2E) refieren a sistemas complejos representados por un
único modelo neuronal profundo ensamblando las capas de preprocesamiento como
capas intermedias del modelo. En particular, este tipo de pruebas se realizaron
en una etapa temprana de la tesis donde la idea de generar ventanas de planes
relajados aún no se había investigado. En particular, se experimentaron con
modelos E2E de FastText donde se agrega una capa de predicción \emph{sigmoide} o
\emph{softmax} al modelo de embeddings para que sean utilizados en
clasificación. No obstante, se optó por descontinuar estos experimentos por no
haber mostrado buenos resultados iniciales. Fueron experimentos prototipos donde
se buscaba verificar la factibilidad del uso de word embeddings en grounding
heurístico. De todas formas, a la luz de lo aprendido en el marco de la tesis,
es quizás una tarea interesante para trabajo futuro revisitar esta idea.

\subsection{El problema de inclusión sobre planes relajados}

Otra estrategia que utilizamos durante el análisis en la generación de ventanas
de planes relajados, fue plantear el problema de clasificación binaria como uno
multiclase. En lugar de sólo 2 clases, manteníamos 4 que representaban la noción
de sí una acción pertenecía al plan relajado, y si era parte de los good
operators del problema. Es decir, una ventana de plan relajado $w$ y acción $a$
es etiquetada como:

\begin{itemize}
    \item 0: Si $a$ no es good operator y no pertenece a $w$.
    \item 1: Si $a$ no es good operator y pertenece a $w$.
    \item 2: Si $a$ es good operator y no pertenece a $w$.
    \item 3: Si $a$ es good operator y pertenece a $w$.
\end{itemize}

Luego al agrupar por ventanas y acción, consideramos como predicción final la
clase $3$ si al menos una de las ventanas predijo $3$. Caso contrario, si para
alguna ventana la predicción fue $2$, la predicción del agrupamiento es $2$. Y así
sucesivamente hasta la clase $0$.

De esta manera obteníamos un resultado similar a la agregación por el máximo que
realizamos en los experimentos. Es decir, si una acción es relevante dada una
ventana del plan relajado, entonces debe serlo dado el plan completo.

Esta idea agrega como información adicional si la acción está en el plan
relajado o no, con la hipótesis de que una acción en el plan relajado tiene más
chances de estar en el plan original. Sin embargo, esto no pareció resultar en
buena performance.

\subsection{Mayorización}

La repetición de ejemplos con etiquetas diferentes puede dificultar el
aprendizaje de un modelo, si no son preprocesadas con alguna técnica de
mayorización. Es decir, de entre todas las repeticiones del mismo ejemplo, pero
con distintas clases, mantener una sola replica preservando la etiqueta que haya
ocurrido en mayor cantidad. Esta técnica fue aplicada para la codificación por
word embeddings, donde una hipótesis para mejorar la separación de los ejemplos
de entrenamiento fue asignar la etiqueta mayoritaria para todo los vectores de
dimensión $D$ (plan relajado, acción) que estén cerca en un rango en
$\mathbb{R}^{D}$.

\subsection{Orden de ventanas como características}

Por último, otra implementación que se agregó al sistema, y que es un patrón
configurable de las etapas de ejecución, es la posibilidad de mantener el orden
en que ocurren las ventanas. Es decir, se agrega un índice en la matriz de
características indicando la posición en el plan relajado como se muestra en el
cuadro \ref{tb:window_order}.

\begin{table}[h!]
\centering
\scalebox{0.9}{
 \begin{tabular}{||c | c | c | c||} 
 \hline
 Plan relajado & Orden de ventana & Acción & Etiqueta \\ [0.5ex] \hline\hline
 %(take_image satellite0 planet5 instrument1 image1)
 {}[-0.04166, -0.26048, ...] & 1 &{}[0.0124, ...] & 1 \\
 {}[0.020155, -0.17644, ...] & 2 &{}[0.0124, ...] & 1 \\
 {}[-0.03441, 0.161433, ...] & 3 &{}[0.0124, ...] & 1  \\
 ... & ... & ... & ...\\ [1ex] 
 \hline
 \end{tabular}}
 \caption{Ejemplos etiquetados a partir de un plan relajado y una acción.}
 \label{tb:window_order}
\end{table}

El objetivo de este experimento fue agregado con el fin de evitar perder la
información del orden durante la creación de las ventanas de un plan relajado y
se buscaba analizar si es un factor importante para el entrenamiento y posterior
evaluación del modelo.